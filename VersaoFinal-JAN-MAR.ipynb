{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f601e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Unnamed: 0</th>\n",
       "      <th colspan=\"8\" halign=\"left\">classification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>848.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>848.0</td>\n",
       "      <td>848.00</td>\n",
       "      <td>848.0</td>\n",
       "      <td>848.00</td>\n",
       "      <td>848.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.0</td>\n",
       "      <td>710.400000</td>\n",
       "      <td>89.226117</td>\n",
       "      <td>669.0</td>\n",
       "      <td>670.00</td>\n",
       "      <td>671.0</td>\n",
       "      <td>672.00</td>\n",
       "      <td>870.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.0</td>\n",
       "      <td>917.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>917.0</td>\n",
       "      <td>917.25</td>\n",
       "      <td>917.5</td>\n",
       "      <td>917.75</td>\n",
       "      <td>918.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2.0</td>\n",
       "      <td>461.500000</td>\n",
       "      <td>637.103210</td>\n",
       "      <td>11.0</td>\n",
       "      <td>236.25</td>\n",
       "      <td>461.5</td>\n",
       "      <td>686.75</td>\n",
       "      <td>912.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.0</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>920.0</td>\n",
       "      <td>920.00</td>\n",
       "      <td>920.0</td>\n",
       "      <td>920.00</td>\n",
       "      <td>920.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3.0</td>\n",
       "      <td>184.333333</td>\n",
       "      <td>137.121601</td>\n",
       "      <td>26.0</td>\n",
       "      <td>144.50</td>\n",
       "      <td>263.0</td>\n",
       "      <td>263.50</td>\n",
       "      <td>264.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2.0</td>\n",
       "      <td>513.000000</td>\n",
       "      <td>511.945310</td>\n",
       "      <td>151.0</td>\n",
       "      <td>332.00</td>\n",
       "      <td>513.0</td>\n",
       "      <td>694.00</td>\n",
       "      <td>875.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2.0</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>41.012193</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.50</td>\n",
       "      <td>95.0</td>\n",
       "      <td>109.50</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2.0</td>\n",
       "      <td>879.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>879.0</td>\n",
       "      <td>879.25</td>\n",
       "      <td>879.5</td>\n",
       "      <td>879.75</td>\n",
       "      <td>880.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>11.0</td>\n",
       "      <td>237.181818</td>\n",
       "      <td>282.374510</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>214.50</td>\n",
       "      <td>888.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>16.753109</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.75</td>\n",
       "      <td>123.0</td>\n",
       "      <td>137.25</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14.0</td>\n",
       "      <td>314.142857</td>\n",
       "      <td>324.221638</td>\n",
       "      <td>24.0</td>\n",
       "      <td>93.25</td>\n",
       "      <td>146.5</td>\n",
       "      <td>334.75</td>\n",
       "      <td>914.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8.0</td>\n",
       "      <td>305.500000</td>\n",
       "      <td>299.970951</td>\n",
       "      <td>22.0</td>\n",
       "      <td>60.50</td>\n",
       "      <td>208.5</td>\n",
       "      <td>510.75</td>\n",
       "      <td>858.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>11.0</td>\n",
       "      <td>524.272727</td>\n",
       "      <td>371.004607</td>\n",
       "      <td>118.0</td>\n",
       "      <td>147.50</td>\n",
       "      <td>778.0</td>\n",
       "      <td>844.00</td>\n",
       "      <td>910.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>12.0</td>\n",
       "      <td>279.916667</td>\n",
       "      <td>221.750662</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.00</td>\n",
       "      <td>264.5</td>\n",
       "      <td>456.25</td>\n",
       "      <td>679.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>13.0</td>\n",
       "      <td>623.153846</td>\n",
       "      <td>336.890646</td>\n",
       "      <td>2.0</td>\n",
       "      <td>393.00</td>\n",
       "      <td>797.0</td>\n",
       "      <td>876.00</td>\n",
       "      <td>925.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3.0</td>\n",
       "      <td>209.666667</td>\n",
       "      <td>263.122278</td>\n",
       "      <td>43.0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>293.00</td>\n",
       "      <td>513.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9.0</td>\n",
       "      <td>320.222222</td>\n",
       "      <td>301.706719</td>\n",
       "      <td>34.0</td>\n",
       "      <td>116.00</td>\n",
       "      <td>136.0</td>\n",
       "      <td>510.00</td>\n",
       "      <td>906.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>19.0</td>\n",
       "      <td>381.842105</td>\n",
       "      <td>183.447620</td>\n",
       "      <td>130.0</td>\n",
       "      <td>251.50</td>\n",
       "      <td>333.0</td>\n",
       "      <td>531.50</td>\n",
       "      <td>866.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                        \\\n",
       "            count        mean         std    min     25%    50%     75%   \n",
       "Length                                                                    \n",
       "46            1.0  848.000000         NaN  848.0  848.00  848.0  848.00   \n",
       "47            5.0  710.400000   89.226117  669.0  670.00  671.0  672.00   \n",
       "48            2.0  917.500000    0.707107  917.0  917.25  917.5  917.75   \n",
       "50            2.0  461.500000  637.103210   11.0  236.25  461.5  686.75   \n",
       "51            1.0   13.000000         NaN   13.0   13.00   13.0   13.00   \n",
       "52            1.0  920.000000         NaN  920.0  920.00  920.0  920.00   \n",
       "54            3.0  184.333333  137.121601   26.0  144.50  263.0  263.50   \n",
       "55            2.0  513.000000  511.945310  151.0  332.00  513.0  694.00   \n",
       "56            2.0   95.000000   41.012193   66.0   80.50   95.0  109.50   \n",
       "57            2.0  879.500000    0.707107  879.0  879.25  879.5  879.75   \n",
       "58           11.0  237.181818  282.374510    5.0   83.00  120.0  214.50   \n",
       "59            4.0  123.000000   16.753109  108.0  108.75  123.0  137.25   \n",
       "60           14.0  314.142857  324.221638   24.0   93.25  146.5  334.75   \n",
       "61            8.0  305.500000  299.970951   22.0   60.50  208.5  510.75   \n",
       "62           11.0  524.272727  371.004607  118.0  147.50  778.0  844.00   \n",
       "63           12.0  279.916667  221.750662   25.0  105.00  264.5  456.25   \n",
       "64           13.0  623.153846  336.890646    2.0  393.00  797.0  876.00   \n",
       "65            3.0  209.666667  263.122278   43.0   58.00   73.0  293.00   \n",
       "66            9.0  320.222222  301.706719   34.0  116.00  136.0  510.00   \n",
       "67           19.0  381.842105  183.447620  130.0  251.50  333.0  531.50   \n",
       "\n",
       "              classification                                     \n",
       "          max          count mean  std  min  25%  50%  75%  max  \n",
       "Length                                                           \n",
       "46      848.0            1.0  1.0  NaN  1.0  1.0  1.0  1.0  1.0  \n",
       "47      870.0            5.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "48      918.0            2.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "50      912.0            2.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "51       13.0            1.0  1.0  NaN  1.0  1.0  1.0  1.0  1.0  \n",
       "52      920.0            1.0  1.0  NaN  1.0  1.0  1.0  1.0  1.0  \n",
       "54      264.0            3.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "55      875.0            2.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "56      124.0            2.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "57      880.0            2.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "58      888.0           11.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "59      138.0            4.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "60      914.0           14.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "61      858.0            8.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "62      910.0           11.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "63      679.0           12.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "64      925.0           13.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "65      513.0            3.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "66      906.0            9.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "67      866.0           19.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"portuguese\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "data = pd.read_csv(r\"clean-boatos.org-2021-01-12.csv\", encoding=\"utf-8\")\n",
    "data['Length'] = data['title'].apply(len)\n",
    "data.groupby('Length').describe().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6839ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.boatos.org/saude/cadastro-conecte-...</td>\n",
       "      <td>2021-01-09 21:02:08</td>\n",
       "      <td>Cadastro do Conecte SUS será obrigatório para ...</td>\n",
       "      <td>Pessoal, todo mundo precisa se cadastrar no co...</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.boatos.org/mundo/cristina-kirchner...</td>\n",
       "      <td>2021-01-09 14:32:34</td>\n",
       "      <td>Cristina Kirchner tomou vacina da Covid-19 sem...</td>\n",
       "      <td>A vice-presidente argentina, é a primeira mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.boatos.org/saude/gerson-camarotti-...</td>\n",
       "      <td>2021-01-08 19:13:52</td>\n",
       "      <td>Gerson Camarotti pediu cassação do registro de...</td>\n",
       "      <td>ESTE SAFADO ESTA PEDINDO PARA OS CONSELHOS T...</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.boatos.org/saude/secretario-saude-...</td>\n",
       "      <td>2021-01-08 16:33:39</td>\n",
       "      <td>Secretário de Saúde de Minas Gerais escreve me...</td>\n",
       "      <td>Mensagem do Secretário Estado Saúde de Minas ...</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.boatos.org/mundo/presidente-pais-l...</td>\n",
       "      <td>2021-01-07 17:51:58</td>\n",
       "      <td>Presidente de país do Leste Europeu se vacinou...</td>\n",
       "      <td>OLHEM ISSO, OS GOVERNANTES COMO SEU DÓRIA, EST...</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               link  \\\n",
       "0           1  https://www.boatos.org/saude/cadastro-conecte-...   \n",
       "1           2  https://www.boatos.org/mundo/cristina-kirchner...   \n",
       "2           3  https://www.boatos.org/saude/gerson-camarotti-...   \n",
       "3           4  https://www.boatos.org/saude/secretario-saude-...   \n",
       "4           5  https://www.boatos.org/mundo/presidente-pais-l...   \n",
       "\n",
       "                  date                                              title  \\\n",
       "0  2021-01-09 21:02:08  Cadastro do Conecte SUS será obrigatório para ...   \n",
       "1  2021-01-09 14:32:34  Cristina Kirchner tomou vacina da Covid-19 sem...   \n",
       "2  2021-01-08 19:13:52  Gerson Camarotti pediu cassação do registro de...   \n",
       "3  2021-01-08 16:33:39  Secretário de Saúde de Minas Gerais escreve me...   \n",
       "4  2021-01-07 17:51:58  Presidente de país do Leste Europeu se vacinou...   \n",
       "\n",
       "                                                text  classification  Length  \n",
       "0  Pessoal, todo mundo precisa se cadastrar no co...               1      73  \n",
       "1   A vice-presidente argentina, é a primeira mul...               1      64  \n",
       "2    ESTE SAFADO ESTA PEDINDO PARA OS CONSELHOS T...               1      97  \n",
       "3   Mensagem do Secretário Estado Saúde de Minas ...               1      72  \n",
       "4  OLHEM ISSO, OS GOVERNANTES COMO SEU DÓRIA, EST...               1      58  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fe2f63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>718</td>\n",
       "      <td>https://www.boatos.org/entretenimento/vidente-...</td>\n",
       "      <td>2020-03-31 17:44:16</td>\n",
       "      <td>Vidente espanhola Nube de María previu quarent...</td>\n",
       "      <td>No dia 24-12-2019, a vidente previu o que ia ...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>719</td>\n",
       "      <td>https://www.boatos.org/religiao/pastor-gerson-...</td>\n",
       "      <td>2020-03-31 15:24:05</td>\n",
       "      <td>Pastor Gerson de Macedo (do Maranhão) fez prof...</td>\n",
       "      <td>O pastor Gerson entregou essa profecia antes ...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>720</td>\n",
       "      <td>https://www.boatos.org/saude/oms-volta-atras-d...</td>\n",
       "      <td>2020-03-31 14:04:12</td>\n",
       "      <td>OMS volta atrás, dá razão a Bolsonaro, pede fi...</td>\n",
       "      <td>BOLSONARO TEM RAZÃO: OMS PERCEBEU QUE FEZ BE...</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>721</td>\n",
       "      <td>https://www.boatos.org/politica/grupo-whatsapp...</td>\n",
       "      <td>2020-03-31 13:26:37</td>\n",
       "      <td>Grupo no WhatsApp Resistência Pará (do PSOL) p...</td>\n",
       "      <td>“~Resistência Pará Di Psol, ~ niltinho, #Lula...</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>723</td>\n",
       "      <td>https://www.boatos.org/mundo/video-tv-italiana...</td>\n",
       "      <td>2020-03-31 09:28:51</td>\n",
       "      <td>Vídeo da TV italiana RAI de 2015 prova que o c...</td>\n",
       "      <td>“Em novembro de 2015 a televisão Italiana apr...</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>929</td>\n",
       "      <td>https://www.boatos.org/mundo/sopa-morcego-wuha...</td>\n",
       "      <td>2020-01-28 23:18:24</td>\n",
       "      <td>Sopa de morcego que foi consumida em Wuhan (Ch...</td>\n",
       "      <td>“QUE TAL? A disseminação do coronavírus entre...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>930</td>\n",
       "      <td>https://www.boatos.org/mundo/sopa-morcego-wuha...</td>\n",
       "      <td>2020-01-28 23:18:24</td>\n",
       "      <td>Sopa de morcego que foi consumida em Wuhan (Ch...</td>\n",
       "      <td>“SOPA DE MORCEGO | Vídeos de pessoas comend...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>931</td>\n",
       "      <td>https://www.boatos.org/saude/diretor-do-hc-pre...</td>\n",
       "      <td>2020-01-27 21:51:19</td>\n",
       "      <td>Diretor do HC, preocupado com nova gripe, reco...</td>\n",
       "      <td>Diretor do HC (Hospital das Clínicas) preocup...</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>932</td>\n",
       "      <td>https://www.boatos.org/saude/coronavirus-10-mi...</td>\n",
       "      <td>2020-01-26 14:28:59</td>\n",
       "      <td>Coronavírus tem 10 mil casos confirmados Brasi...</td>\n",
       "      <td>URGENTE: VÍRUS DA CHINA ( CORONAVÍRUS) 10 MIL...</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>933</td>\n",
       "      <td>https://www.boatos.org/mundo/coronavirus-28-mi...</td>\n",
       "      <td>2020-01-26 13:54:45</td>\n",
       "      <td>Coronavírus tem 2,8 milhões de infectados e ma...</td>\n",
       "      <td>URGENTÍSSIMO: 2,8 MILHÕES INFECTADOS PELO COR...</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               link  \\\n",
       "542         718  https://www.boatos.org/entretenimento/vidente-...   \n",
       "543         719  https://www.boatos.org/religiao/pastor-gerson-...   \n",
       "544         720  https://www.boatos.org/saude/oms-volta-atras-d...   \n",
       "545         721  https://www.boatos.org/politica/grupo-whatsapp...   \n",
       "546         723  https://www.boatos.org/mundo/video-tv-italiana...   \n",
       "..          ...                                                ...   \n",
       "709         929  https://www.boatos.org/mundo/sopa-morcego-wuha...   \n",
       "710         930  https://www.boatos.org/mundo/sopa-morcego-wuha...   \n",
       "711         931  https://www.boatos.org/saude/diretor-do-hc-pre...   \n",
       "712         932  https://www.boatos.org/saude/coronavirus-10-mi...   \n",
       "713         933  https://www.boatos.org/mundo/coronavirus-28-mi...   \n",
       "\n",
       "                   date                                              title  \\\n",
       "542 2020-03-31 17:44:16  Vidente espanhola Nube de María previu quarent...   \n",
       "543 2020-03-31 15:24:05  Pastor Gerson de Macedo (do Maranhão) fez prof...   \n",
       "544 2020-03-31 14:04:12  OMS volta atrás, dá razão a Bolsonaro, pede fi...   \n",
       "545 2020-03-31 13:26:37  Grupo no WhatsApp Resistência Pará (do PSOL) p...   \n",
       "546 2020-03-31 09:28:51  Vídeo da TV italiana RAI de 2015 prova que o c...   \n",
       "..                  ...                                                ...   \n",
       "709 2020-01-28 23:18:24  Sopa de morcego que foi consumida em Wuhan (Ch...   \n",
       "710 2020-01-28 23:18:24  Sopa de morcego que foi consumida em Wuhan (Ch...   \n",
       "711 2020-01-27 21:51:19  Diretor do HC, preocupado com nova gripe, reco...   \n",
       "712 2020-01-26 14:28:59  Coronavírus tem 10 mil casos confirmados Brasi...   \n",
       "713 2020-01-26 13:54:45  Coronavírus tem 2,8 milhões de infectados e ma...   \n",
       "\n",
       "                                                  text  classification  Length  \n",
       "542   No dia 24-12-2019, a vidente previu o que ia ...               1      76  \n",
       "543   O pastor Gerson entregou essa profecia antes ...               1      95  \n",
       "544    BOLSONARO TEM RAZÃO: OMS PERCEBEU QUE FEZ BE...               1     107  \n",
       "545   “~Resistência Pará Di Psol, ~ niltinho, #Lula...               1      86  \n",
       "546   “Em novembro de 2015 a televisão Italiana apr...               1     103  \n",
       "..                                                 ...             ...     ...  \n",
       "709   “QUE TAL? A disseminação do coronavírus entre...               1      76  \n",
       "710     “SOPA DE MORCEGO | Vídeos de pessoas comend...               1      76  \n",
       "711   Diretor do HC (Hospital das Clínicas) preocup...               1      89  \n",
       "712   URGENTE: VÍRUS DA CHINA ( CORONAVÍRUS) 10 MIL...               1      70  \n",
       "713   URGENTÍSSIMO: 2,8 MILHÕES INFECTADOS PELO COR...               1      75  \n",
       "\n",
       "[172 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "filtered_jan_mar = data.loc[(data['date'] >= '2020-01-26') & (data['date'] <= '2020-04-01')]\n",
    "filtered_jan_mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40e49a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542    vident espanhol nub de marí prev quarenten em ...\n",
      "543    pastor gerson de maced ( do maranhã ) fez prof...\n",
      "544    oms volt atrás , dá razã a bolsonar , ped fim ...\n",
      "545    grup no whatsapp resistent par ( do psol ) pla...\n",
      "546    víd da tv italian rai de 2015 prov que o coron...\n",
      "                             ...                        \n",
      "709    sop de morceg que foi consum em wuhan ( chin )...\n",
      "710    sop de morceg que foi consum em wuhan ( chin )...\n",
      "711    diretor do hc , preocup com nov grip , recomen...\n",
      "712    coronavírus tem 10 mil cas confirm brasil e 28...\n",
      "713    coronavírus tem 2,8 milhõ de infect e mat 112 ...\n",
      "Name: title, Length: 172, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daniela/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/tmp/ipykernel_52952/1672737613.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_jan_mar['title'] = filtered_jan_mar['title'].apply(word_tokenize)\n",
      "/tmp/ipykernel_52952/1672737613.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_jan_mar['title'] = filtered_jan_mar['title'].apply(lambda x: ' '.join([snowball.stem(y) for y in x]))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import tokenize \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer(language=\"portuguese\")\n",
    "\n",
    "filtered_jan_mar['title'] = filtered_jan_mar['title'].apply(word_tokenize)\n",
    "filtered_jan_mar['title'] = filtered_jan_mar['title'].apply(lambda x: ' '.join([snowball.stem(y) for y in x]))\n",
    "print(filtered_jan_mar['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7e3e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.10/site-packages/texthero/preprocessing.py:105: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(pattern, symbols)\n",
      "/home/daniela/.local/lib/python3.10/site-packages/texthero/preprocessing.py:661: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(pattern, \"\")\n",
      "/home/daniela/.local/lib/python3.10/site-packages/texthero/preprocessing.py:173: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(rf\"([{string.punctuation}])+\", symbol)\n",
      "/home/daniela/.local/lib/python3.10/site-packages/texthero/preprocessing.py:693: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(pattern, r\"\\2 \\3 \\4 \\5\").str.split()\n",
      "/home/daniela/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_52952/1446553537.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_jan_mar[\"PCA\"] = (\n"
     ]
    }
   ],
   "source": [
    "import texthero as hero # text hero  \n",
    "filtered_jan_mar[\"PCA\"] = (\n",
    "            filtered_jan_mar['title']\n",
    "            .pipe(hero.clean)\n",
    "            .pipe(hero.tfidf) # term frequency and inverse document frequency \n",
    "            .pipe(hero.pca)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9996877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>Length</th>\n",
       "      <th>PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>718</td>\n",
       "      <td>https://www.boatos.org/entretenimento/vidente-...</td>\n",
       "      <td>2020-03-31 17:44:16</td>\n",
       "      <td>vident espanhol nub de marí prev quarenten em ...</td>\n",
       "      <td>No dia 24-12-2019, a vidente previu o que ia ...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>[0.22302603688572664, -0.967277422518552]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>719</td>\n",
       "      <td>https://www.boatos.org/religiao/pastor-gerson-...</td>\n",
       "      <td>2020-03-31 15:24:05</td>\n",
       "      <td>pastor gerson de maced ( do maranhã ) fez prof...</td>\n",
       "      <td>O pastor Gerson entregou essa profecia antes ...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>[1.3427384020332978, -0.5043682407694777]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>720</td>\n",
       "      <td>https://www.boatos.org/saude/oms-volta-atras-d...</td>\n",
       "      <td>2020-03-31 14:04:12</td>\n",
       "      <td>oms volt atrás , dá razã a bolsonar , ped fim ...</td>\n",
       "      <td>BOLSONARO TEM RAZÃO: OMS PERCEBEU QUE FEZ BE...</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>[1.8200959949769213, 2.8166917212293234]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>721</td>\n",
       "      <td>https://www.boatos.org/politica/grupo-whatsapp...</td>\n",
       "      <td>2020-03-31 13:26:37</td>\n",
       "      <td>grup no whatsapp resistent par ( do psol ) pla...</td>\n",
       "      <td>“~Resistência Pará Di Psol, ~ niltinho, #Lula...</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>[0.45523256373724186, -1.882735618164629]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>723</td>\n",
       "      <td>https://www.boatos.org/mundo/video-tv-italiana...</td>\n",
       "      <td>2020-03-31 09:28:51</td>\n",
       "      <td>víd da tv italian rai de 2015 prov que o coron...</td>\n",
       "      <td>“Em novembro de 2015 a televisão Italiana apr...</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>[-1.7639011710506582, 3.0004138163162093]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>929</td>\n",
       "      <td>https://www.boatos.org/mundo/sopa-morcego-wuha...</td>\n",
       "      <td>2020-01-28 23:18:24</td>\n",
       "      <td>sop de morceg que foi consum em wuhan ( chin )...</td>\n",
       "      <td>“QUE TAL? A disseminação do coronavírus entre...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>[-0.9841579172252594, 0.5072133969781775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>930</td>\n",
       "      <td>https://www.boatos.org/mundo/sopa-morcego-wuha...</td>\n",
       "      <td>2020-01-28 23:18:24</td>\n",
       "      <td>sop de morceg que foi consum em wuhan ( chin )...</td>\n",
       "      <td>“SOPA DE MORCEGO | Vídeos de pessoas comend...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>[-0.9841579172252594, 0.5072133969781775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>931</td>\n",
       "      <td>https://www.boatos.org/saude/diretor-do-hc-pre...</td>\n",
       "      <td>2020-01-27 21:51:19</td>\n",
       "      <td>diretor do hc , preocup com nov grip , recomen...</td>\n",
       "      <td>Diretor do HC (Hospital das Clínicas) preocup...</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>[-0.2884145464139571, -1.5773689253474232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>932</td>\n",
       "      <td>https://www.boatos.org/saude/coronavirus-10-mi...</td>\n",
       "      <td>2020-01-26 14:28:59</td>\n",
       "      <td>coronavírus tem 10 mil cas confirm brasil e 28...</td>\n",
       "      <td>URGENTE: VÍRUS DA CHINA ( CORONAVÍRUS) 10 MIL...</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>[-0.3497464505587083, -0.6588444052630676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>933</td>\n",
       "      <td>https://www.boatos.org/mundo/coronavirus-28-mi...</td>\n",
       "      <td>2020-01-26 13:54:45</td>\n",
       "      <td>coronavírus tem 2,8 milhõ de infect e mat 112 ...</td>\n",
       "      <td>URGENTÍSSIMO: 2,8 MILHÕES INFECTADOS PELO COR...</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>[-0.6952375339910236, 0.09282828089278125]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               link  \\\n",
       "542         718  https://www.boatos.org/entretenimento/vidente-...   \n",
       "543         719  https://www.boatos.org/religiao/pastor-gerson-...   \n",
       "544         720  https://www.boatos.org/saude/oms-volta-atras-d...   \n",
       "545         721  https://www.boatos.org/politica/grupo-whatsapp...   \n",
       "546         723  https://www.boatos.org/mundo/video-tv-italiana...   \n",
       "..          ...                                                ...   \n",
       "709         929  https://www.boatos.org/mundo/sopa-morcego-wuha...   \n",
       "710         930  https://www.boatos.org/mundo/sopa-morcego-wuha...   \n",
       "711         931  https://www.boatos.org/saude/diretor-do-hc-pre...   \n",
       "712         932  https://www.boatos.org/saude/coronavirus-10-mi...   \n",
       "713         933  https://www.boatos.org/mundo/coronavirus-28-mi...   \n",
       "\n",
       "                   date                                              title  \\\n",
       "542 2020-03-31 17:44:16  vident espanhol nub de marí prev quarenten em ...   \n",
       "543 2020-03-31 15:24:05  pastor gerson de maced ( do maranhã ) fez prof...   \n",
       "544 2020-03-31 14:04:12  oms volt atrás , dá razã a bolsonar , ped fim ...   \n",
       "545 2020-03-31 13:26:37  grup no whatsapp resistent par ( do psol ) pla...   \n",
       "546 2020-03-31 09:28:51  víd da tv italian rai de 2015 prov que o coron...   \n",
       "..                  ...                                                ...   \n",
       "709 2020-01-28 23:18:24  sop de morceg que foi consum em wuhan ( chin )...   \n",
       "710 2020-01-28 23:18:24  sop de morceg que foi consum em wuhan ( chin )...   \n",
       "711 2020-01-27 21:51:19  diretor do hc , preocup com nov grip , recomen...   \n",
       "712 2020-01-26 14:28:59  coronavírus tem 10 mil cas confirm brasil e 28...   \n",
       "713 2020-01-26 13:54:45  coronavírus tem 2,8 milhõ de infect e mat 112 ...   \n",
       "\n",
       "                                                  text  classification  \\\n",
       "542   No dia 24-12-2019, a vidente previu o que ia ...               1   \n",
       "543   O pastor Gerson entregou essa profecia antes ...               1   \n",
       "544    BOLSONARO TEM RAZÃO: OMS PERCEBEU QUE FEZ BE...               1   \n",
       "545   “~Resistência Pará Di Psol, ~ niltinho, #Lula...               1   \n",
       "546   “Em novembro de 2015 a televisão Italiana apr...               1   \n",
       "..                                                 ...             ...   \n",
       "709   “QUE TAL? A disseminação do coronavírus entre...               1   \n",
       "710     “SOPA DE MORCEGO | Vídeos de pessoas comend...               1   \n",
       "711   Diretor do HC (Hospital das Clínicas) preocup...               1   \n",
       "712   URGENTE: VÍRUS DA CHINA ( CORONAVÍRUS) 10 MIL...               1   \n",
       "713   URGENTÍSSIMO: 2,8 MILHÕES INFECTADOS PELO COR...               1   \n",
       "\n",
       "     Length                                         PCA  \n",
       "542      76   [0.22302603688572664, -0.967277422518552]  \n",
       "543      95   [1.3427384020332978, -0.5043682407694777]  \n",
       "544     107    [1.8200959949769213, 2.8166917212293234]  \n",
       "545      86   [0.45523256373724186, -1.882735618164629]  \n",
       "546     103   [-1.7639011710506582, 3.0004138163162093]  \n",
       "..      ...                                         ...  \n",
       "709      76   [-0.9841579172252594, 0.5072133969781775]  \n",
       "710      76   [-0.9841579172252594, 0.5072133969781775]  \n",
       "711      89  [-0.2884145464139571, -1.5773689253474232]  \n",
       "712      70  [-0.3497464505587083, -0.6588444052630676]  \n",
       "713      75  [-0.6952375339910236, 0.09282828089278125]  \n",
       "\n",
       "[172 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_jan_mar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe6a95",
   "metadata": {},
   "source": [
    "# K-MEANS\n",
    "\n",
    "## N = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be54966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (172, 598)\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " coronavírus\n",
      " nov\n",
      " par\n",
      " 19\n",
      " covid\n",
      " chin\n",
      " cur\n",
      " caus\n",
      " prov\n",
      " bolsonar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "custom_stop_words = ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'é', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estão', 'você', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'será', 'nós', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=custom_stop_words, max_features = 2000)\n",
    "X = vectorizer.fit_transform(filtered_jan_mar['title'])\n",
    "\n",
    "# getting the shape of X\n",
    "print(\"Shape of X :\", X.shape)\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "true_k = 1\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076fd4b",
   "metadata": {},
   "source": [
    "## N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d485c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " coronavírus\n",
      " nov\n",
      " covid\n",
      " 19\n",
      " chin\n",
      " cur\n",
      " caus\n",
      " prov\n",
      " prev\n",
      " mat\n",
      "Cluster 1:\n",
      " par\n",
      " bolsonar\n",
      " ped\n",
      " mai\n",
      " áudi\n",
      " coronavírus\n",
      " estã\n",
      " cert\n",
      " volt\n",
      " infect\n"
     ]
    }
   ],
   "source": [
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda0cd2",
   "metadata": {},
   "source": [
    "## N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45d64a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " nov\n",
      " coronavírus\n",
      " diretor\n",
      " bill\n",
      " patent\n",
      " gat\n",
      " empres\n",
      " divulg\n",
      " don\n",
      " sobr\n",
      "Cluster 1:\n",
      " par\n",
      " coronavírus\n",
      " nov\n",
      " vacin\n",
      " 19\n",
      " covid\n",
      " cur\n",
      " bolsonar\n",
      " test\n",
      " hemoterap\n",
      "Cluster 2:\n",
      " coronavírus\n",
      " chin\n",
      " prov\n",
      " covid\n",
      " 19\n",
      " mat\n",
      " mostr\n",
      " prev\n",
      " exist\n",
      " caus\n"
     ]
    }
   ],
   "source": [
    "true_k = 3\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7095d079",
   "metadata": {},
   "source": [
    "## N = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "545668ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " contr\n",
      " recomend\n",
      " chá\n",
      " crianc\n",
      " whatsapp\n",
      " biólog\n",
      " coronavírus\n",
      " par\n",
      " gel\n",
      " álcool\n",
      "Cluster 1:\n",
      " caus\n",
      " chin\n",
      " coronavírus\n",
      " pesso\n",
      " mostr\n",
      " par\n",
      " ped\n",
      " quarenten\n",
      " áudi\n",
      " bolsonar\n",
      "Cluster 2:\n",
      " sobr\n",
      " cheg\n",
      " coronavírus\n",
      " itál\n",
      " chines\n",
      " prev\n",
      " dic\n",
      " livr\n",
      " divulg\n",
      " 1981\n",
      "Cluster 3:\n",
      " coronavírus\n",
      " nov\n",
      " covid\n",
      " 19\n",
      " prov\n",
      " cur\n",
      " exist\n",
      " mat\n",
      " chin\n",
      " armaçã\n"
     ]
    }
   ],
   "source": [
    "true_k = 4\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4b31d",
   "metadata": {},
   "source": [
    "## N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a41526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " par\n",
      " mai\n",
      " estã\n",
      " coronavírus\n",
      " cri\n",
      " bolsonar\n",
      " chin\n",
      " após\n",
      " infect\n",
      " italian\n",
      "Cluster 1:\n",
      " nov\n",
      " caus\n",
      " coronavírus\n",
      " 19\n",
      " covid\n",
      " sã\n",
      " cur\n",
      " prov\n",
      " pesso\n",
      " paul\n",
      "Cluster 2:\n",
      " diz\n",
      " sobr\n",
      " coronavírus\n",
      " president\n",
      " nov\n",
      " york\n",
      " faz\n",
      " fal\n",
      " dic\n",
      " vai\n",
      "Cluster 3:\n",
      " ped\n",
      " mar\n",
      " volt\n",
      " áudi\n",
      " grav\n",
      " ricard\n",
      " bolsonar\n",
      " cear\n",
      " camil\n",
      " sistem\n",
      "Cluster 4:\n",
      " coronavírus\n",
      " prev\n",
      " cheg\n",
      " mat\n",
      " livr\n",
      " chin\n",
      " nã\n",
      " 1981\n",
      " 2003\n",
      " revist\n"
     ]
    }
   ],
   "source": [
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b1f3c",
   "metadata": {},
   "source": [
    "## N = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dc3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " whatsapp\n",
      " sit\n",
      " auxíli\n",
      " liber\n",
      " emergencial\n",
      " govern\n",
      " grac\n",
      " distribu\n",
      " grup\n",
      " planej\n",
      "Cluster 1:\n",
      " crianc\n",
      " registr\n",
      " weintraub\n",
      " abrah\n",
      " ministr\n",
      " aul\n",
      " escol\n",
      " educ\n",
      " volt\n",
      " sp\n",
      "Cluster 2:\n",
      " coronavírus\n",
      " nov\n",
      " par\n",
      " cur\n",
      " bolsonar\n",
      " mat\n",
      " sobr\n",
      " cheg\n",
      " livr\n",
      " prev\n",
      "Cluster 3:\n",
      " chin\n",
      " mostr\n",
      " víd\n",
      " sop\n",
      " caus\n",
      " wuhan\n",
      " fot\n",
      " morceg\n",
      " sã\n",
      " ceagesp\n",
      "Cluster 4:\n",
      " diz\n",
      " quarenten\n",
      " vai\n",
      " coronavírus\n",
      " rua\n",
      " áudi\n",
      " sobr\n",
      " normal\n",
      " maior\n",
      " continu\n",
      "Cluster 5:\n",
      " prov\n",
      " 19\n",
      " covid\n",
      " exist\n",
      " armaçã\n",
      " 2003\n",
      " saúd\n",
      " revist\n",
      " chin\n",
      " coronavírus\n"
     ]
    }
   ],
   "source": [
    "true_k = 6\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a813f40",
   "metadata": {},
   "source": [
    "## N = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d9e91bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " bolsonar\n",
      " par\n",
      " ricard\n",
      " grav\n",
      " cri\n",
      " ped\n",
      " áudi\n",
      " camil\n",
      " sistem\n",
      " cear\n",
      "Cluster 1:\n",
      " diz\n",
      " recomend\n",
      " president\n",
      " coronavírus\n",
      " erva\n",
      " doc\n",
      " hc\n",
      " vitamin\n",
      " diretor\n",
      " faz\n",
      "Cluster 2:\n",
      " 19\n",
      " covid\n",
      " prov\n",
      " coronavírus\n",
      " exist\n",
      " nov\n",
      " chin\n",
      " cur\n",
      " armaçã\n",
      " revist\n",
      "Cluster 3:\n",
      " estã\n",
      " par\n",
      " hospital\n",
      " mai\n",
      " infect\n",
      " coronavírus\n",
      " rodrig\n",
      " após\n",
      " lul\n",
      " encontr\n",
      "Cluster 4:\n",
      " mat\n",
      " nã\n",
      " coronavírus\n",
      " gel\n",
      " álcool\n",
      " mil\n",
      " outr\n",
      " chin\n",
      " após\n",
      " vinagr\n",
      "Cluster 5:\n",
      " coronavírus\n",
      " sobr\n",
      " nov\n",
      " cheg\n",
      " itál\n",
      " prev\n",
      " dic\n",
      " livr\n",
      " patent\n",
      " gat\n",
      "Cluster 6:\n",
      " caus\n",
      " mostr\n",
      " víd\n",
      " sã\n",
      " chin\n",
      " quarenten\n",
      " sop\n",
      " wuhan\n",
      " coronavírus\n",
      " paul\n"
     ]
    }
   ],
   "source": [
    "true_k = 7\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44eb910",
   "metadata": {},
   "source": [
    "## N = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0da80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " sã\n",
      " sobr\n",
      " paul\n",
      " caus\n",
      " fal\n",
      " jog\n",
      " ceagesp\n",
      " ceas\n",
      " nov\n",
      " coronavírus\n",
      "Cluster 1:\n",
      " mostr\n",
      " volt\n",
      " víd\n",
      " fot\n",
      " ped\n",
      " chin\n",
      " abrah\n",
      " ministr\n",
      " escol\n",
      " educ\n",
      "Cluster 2:\n",
      " quarenten\n",
      " vai\n",
      " don\n",
      " diz\n",
      " gat\n",
      " patent\n",
      " bill\n",
      " coronavírus\n",
      " empres\n",
      " nov\n",
      "Cluster 3:\n",
      " nov\n",
      " covid\n",
      " 19\n",
      " coronavírus\n",
      " cur\n",
      " prov\n",
      " auto\n",
      " hemoterap\n",
      " previn\n",
      " 2018\n",
      "Cluster 4:\n",
      " prev\n",
      " livr\n",
      " cheg\n",
      " 1981\n",
      " the\n",
      " coronavírus\n",
      " koontz\n",
      " of\n",
      " dean\n",
      " darkness\n",
      "Cluster 5:\n",
      " coronavírus\n",
      " bolsonar\n",
      " mat\n",
      " par\n",
      " nã\n",
      " infect\n",
      " mai\n",
      " estã\n",
      " lul\n",
      " rodrig\n",
      "Cluster 6:\n",
      " chin\n",
      " prov\n",
      " armaçã\n",
      " revist\n",
      " coronavírus\n",
      " 2003\n",
      " covid\n",
      " 19\n",
      " saúd\n",
      " exist\n",
      "Cluster 7:\n",
      " hospital\n",
      " nov\n",
      " diretor\n",
      " stanford\n",
      " divulg\n",
      " encontr\n",
      " coronavírus\n",
      " cur\n",
      " eua\n",
      " após\n"
     ]
    }
   ],
   "source": [
    "true_k = 8\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19547a2a",
   "metadata": {},
   "source": [
    "## N = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bea37b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " whatsapp\n",
      " águ\n",
      " biólog\n",
      " sit\n",
      " auxíli\n",
      " liber\n",
      " gargarej\n",
      " govern\n",
      " emergencial\n",
      " futebol\n",
      "Cluster 1:\n",
      " bolsonar\n",
      " mai\n",
      " infect\n",
      " estã\n",
      " par\n",
      " lul\n",
      " cert\n",
      " grav\n",
      " ricard\n",
      " rodrig\n",
      "Cluster 2:\n",
      " mat\n",
      " nã\n",
      " coronavírus\n",
      " mil\n",
      " vírus\n",
      " chin\n",
      " autoriz\n",
      " tribunal\n",
      " 20\n",
      " ninguém\n",
      "Cluster 3:\n",
      " mostr\n",
      " volt\n",
      " víd\n",
      " ped\n",
      " fot\n",
      " chin\n",
      " escol\n",
      " abrah\n",
      " weintraub\n",
      " ministr\n",
      "Cluster 4:\n",
      " nov\n",
      " contr\n",
      " coronavírus\n",
      " vacin\n",
      " stanford\n",
      " eua\n",
      " hospital\n",
      " cur\n",
      " diretor\n",
      " gat\n",
      "Cluster 5:\n",
      " covid\n",
      " 19\n",
      " prov\n",
      " nov\n",
      " exist\n",
      " coronavírus\n",
      " chin\n",
      " armaçã\n",
      " revist\n",
      " 2003\n",
      "Cluster 6:\n",
      " caus\n",
      " sã\n",
      " coronavírus\n",
      " registr\n",
      " supermerc\n",
      " morceg\n",
      " paul\n",
      " chin\n",
      " mostr\n",
      " ceagesp\n",
      "Cluster 7:\n",
      " prev\n",
      " coronavírus\n",
      " cheg\n",
      " livr\n",
      " 1981\n",
      " sobr\n",
      " diz\n",
      " quarenten\n",
      " rua\n",
      " médic\n",
      "Cluster 8:\n",
      " par\n",
      " chines\n",
      " espalh\n",
      " cusp\n",
      " públic\n",
      " elev\n",
      " loc\n",
      " cas\n",
      " estã\n",
      " hospital\n"
     ]
    }
   ],
   "source": [
    "true_k = 9\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b8ae3",
   "metadata": {},
   "source": [
    "## N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6518038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " sobr\n",
      " pesso\n",
      " coronavírus\n",
      " respir\n",
      " sã\n",
      " ruas\n",
      " test\n",
      " dic\n",
      " canad\n",
      " caíd\n",
      "Cluster 1:\n",
      " caus\n",
      " sã\n",
      " supermerc\n",
      " registr\n",
      " ceas\n",
      " ceagesp\n",
      " jog\n",
      " quarenten\n",
      " aliment\n",
      " paul\n",
      "Cluster 2:\n",
      " prov\n",
      " chin\n",
      " covid\n",
      " 19\n",
      " exist\n",
      " armaçã\n",
      " mostr\n",
      " 2003\n",
      " víd\n",
      " saúd\n",
      "Cluster 3:\n",
      " don\n",
      " empres\n",
      " patent\n",
      " gat\n",
      " bill\n",
      " nov\n",
      " coronavírus\n",
      " diz\n",
      " ocident\n",
      " oper\n",
      "Cluster 4:\n",
      " prev\n",
      " cheg\n",
      " livr\n",
      " 1981\n",
      " coronavírus\n",
      " darkness\n",
      " eyes\n",
      " koontz\n",
      " of\n",
      " dean\n",
      "Cluster 5:\n",
      " recomend\n",
      " diretor\n",
      " contr\n",
      " hc\n",
      " erva\n",
      " doc\n",
      " vitamin\n",
      " chá\n",
      " grip\n",
      " lail\n",
      "Cluster 6:\n",
      " whatsapp\n",
      " sit\n",
      " auxíli\n",
      " liber\n",
      " isol\n",
      " fabric\n",
      " ambev\n",
      " par\n",
      " emergencial\n",
      " vacin\n",
      "Cluster 7:\n",
      " coronavírus\n",
      " cur\n",
      " nov\n",
      " covid\n",
      " 19\n",
      " previn\n",
      " test\n",
      " auto\n",
      " hemoterap\n",
      " eua\n",
      "Cluster 8:\n",
      " mat\n",
      " nã\n",
      " coronavírus\n",
      " mil\n",
      " vírus\n",
      " autoriz\n",
      " tribunal\n",
      " 20\n",
      " chin\n",
      " letal\n",
      "Cluster 9:\n",
      " bolsonar\n",
      " mai\n",
      " estã\n",
      " par\n",
      " infect\n",
      " lul\n",
      " cert\n",
      " ricard\n",
      " grav\n",
      " coronavírus\n"
     ]
    }
   ],
   "source": [
    "true_k = 10\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47eea9ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:441\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/algorithms.py:818\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    816\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 818\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/algorithms.py:574\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    573\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 574\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5943\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5857\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(df.shape) # (714, 6)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_jan_mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiltered_jan_mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobject\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,k):\n\u001b[1;32m     12\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters \u001b[38;5;241m=\u001b[39m i)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:192\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (col, pre, sep) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[1;32m    202\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:228\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Series avoids inconsistent NaN handling\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m codes, levels \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_from_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:2980\u001b[0m, in \u001b[0;36mfactorize_from_iterable\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2975\u001b[0m     codes \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcodes\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2977\u001b[0m     \u001b[38;5;66;03m# The value of ordered is irrelevant since we don't use cat as such,\u001b[39;00m\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;66;03m# but only the resulting categories, the order of which is independent\u001b[39;00m\n\u001b[1;32m   2979\u001b[0m     \u001b[38;5;66;03m# from ordered. Set ordered to False as default. See GH #15457\u001b[39;00m\n\u001b[0;32m-> 2980\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2981\u001b[0m     categories \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcategories\n\u001b[1;32m   2982\u001b[0m     codes \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcodes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:443\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    441\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 443\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mordered:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;66;03m# raise, as we don't have a sortable data structure and so\u001b[39;00m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# the user should give us one by specifying categories\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not ordered, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicitly specify the categories order \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby passing in a categories argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/algorithms.py:818\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    816\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 818\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m na_sentinel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;66;03m# TODO: Can remove when na_sentinel=na_sentinel as in TODO above\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/algorithms.py:574\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    571\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    573\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 574\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    583\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5943\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5857\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# print(df.shape) # (714, 6)\n",
    "\n",
    "x = []\n",
    "final_df = pd.get_dummies(filtered_jan_mar, columns=filtered_jan_mar.select_dtypes(['object']).columns)\n",
    "\n",
    "for i in range(1,k):\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    kmeans.fit(final_df)\n",
    "    x.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,k), 30)\n",
    "plt.title('The elbow method')\n",
    "plt.xlabel('The number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
